2025-05-26 01:39:48,791 - mmseg - INFO - Multi-processing start method is `None`
2025-05-26 01:39:48,801 - mmseg - INFO - OpenCV num_threads is `8
2025-05-26 01:39:48,801 - mmseg - INFO - OMP num threads is 1
2025-05-26 01:39:48,846 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (GCC) 11.2.1 20220127 (Red Hat 11.2.1-9)
PyTorch: 2.5.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

TorchVision: 0.20.1
OpenCV: 4.11.0
MMCV: 1.7.2
MMCV Compiler: GCC 11.2
MMCV CUDA Compiler: not available
MMSegmentation: 0.30.0+87c7791
------------------------------------------------------------

2025-05-26 01:39:48,846 - mmseg - INFO - Distributed training: True
2025-05-26 01:39:49,124 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='DTP',
    pretrained=None,
    backbone=dict(
        type='SwinTransformer',
        pretrain_img_size=192,
        embed_dims=128,
        patch_size=4,
        window_size=6,
        mlp_ratio=4,
        depths=[2, 2, 18, 2],
        num_heads=[4, 8, 16, 32],
        strides=(4, 2, 2, 2),
        out_indices=(0, 1, 2, 3),
        qkv_bias=True,
        qk_scale=None,
        patch_norm=True,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.3,
        use_abs_pos_embed=False,
        act_cfg=dict(type='GELU'),
        norm_cfg=dict(type='LN', requires_grad=True),
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'checkpoints/simmim_pretrain__swin_base__img192_window6__800ep.pth'
        )),
    decode_head=dict(
        type='IAParser',
        in_channels=[128, 256, 512, 1024],
        in_index=[0, 1, 2, 3],
        pool_scales=(1, 2, 3, 6),
        channels=512,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=1.0,
            avg_non_ignore=True),
        illumination_channels=128,
        illumination_features_channels=64),
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=384,
        in_index=2,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 1024), stride=(341, 683)),
    disturb_beta='uniform',
    disentangle_loss=dict(type='PixelLoss', loss_weight=0.1, loss_type='L1'),
    disentangle_head=dict(
        type='SODHead',
        channels=32,
        in_channels=4,
        ill_embeds_op='-',
        clip=False,
        norm_cfg=dict(type='IN2d', requires_grad=True),
        init_cfg=dict(
            type='Kaiming',
            override=dict(
                type='Constant',
                layer='Conv2d',
                name='reflectance_output',
                val=0.0,
                bias=0.5)),
        loss_smooth=dict(type='SmoothLoss', loss_weight=0.01),
        loss_retinex=dict(type='PixelLoss', loss_weight=1.0, loss_type='L2')))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(256, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
nightlab_train = dict(
    type='NightcityDataset',
    data_root='data/nightcity-fine/train',
    img_dir='img',
    ann_dir='lbl',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(type='Resize', img_scale=(1024, 512), ratio_range=(0.5, 2.0)),
        dict(type='RandomCrop', crop_size=(256, 512), cat_max_ratio=0.75),
        dict(type='RandomFlip', prob=0.5),
        dict(type='PhotoMetricDistortion'),
        dict(
            type='Normalize',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True),
        dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
        dict(type='DefaultFormatBundle'),
        dict(type='Collect', keys=['img', 'gt_semantic_seg'])
    ])
nightlab_test = dict(
    type='NightcityDataset',
    data_root='data/nightcity-fine/val',
    img_dir='img',
    ann_dir='lbl',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            type='MultiScaleFlipAug',
            img_scale=(1024, 512),
            flip=False,
            transforms=[
                dict(type='Resize', keep_ratio=True),
                dict(type='RandomFlip'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='ImageToTensor', keys=['img']),
                dict(type='Collect', keys=['img'])
            ])
    ])
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='DTPDataset',
        datasetA=dict(
            type='NightcityDataset',
            data_root='data/nightcity-fine/train',
            img_dir='img',
            ann_dir='lbl',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(
                    type='Resize',
                    img_scale=(1024, 512),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(256, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ]),
        datasetB=dict(
            type='NightcityDataset',
            data_root='data/nightcity-fine/train',
            img_dir='img',
            ann_dir='lbl',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(
                    type='Resize',
                    img_scale=(1024, 512),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(256, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='NightcityDataset',
        data_root='data/nightcity-fine/val',
        img_dir='img',
        ann_dir='lbl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='NightcityDataset',
        data_root='data/nightcity-fine/val',
        img_dir='img',
        ann_dir='lbl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=False),
        dict(type='TensorboardLoggerHook')
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=60000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=3)
evaluation = dict(
    interval=2000, metric='mIoU', pre_eval=True, save_best='mIoU')
checkpoint_file = 'checkpoints/simmim_pretrain__swin_base__img192_window6__800ep.pth'
fp16 = dict()
find_unused_parameters = True
gpu_ids = range(0, 2)
load_from = None
resume_from = 'work_dirs/night_base/latest.pth'
auto_resume = False
work_dir = './work_dirs/night_base'

2025-05-26 01:39:49,126 - mmseg - INFO - Set random seed to 42, deterministic: False
2025-05-26 01:39:50,727 - mmseg - INFO - load checkpoint from local path: checkpoints/simmim_pretrain__swin_base__img192_window6__800ep.pth
2025-05-26 01:39:53,340 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: mask_token, norm.weight, norm.bias, stages.0.blocks.1.attn_mask, stages.1.blocks.1.attn_mask, stages.2.blocks.1.attn_mask, stages.2.blocks.3.attn_mask, stages.2.blocks.5.attn_mask, stages.2.blocks.7.attn_mask, stages.2.blocks.9.attn_mask, stages.2.blocks.11.attn_mask, stages.2.blocks.13.attn_mask, stages.2.blocks.15.attn_mask, stages.2.blocks.17.attn_mask

missing keys in source state_dict: norm0.weight, norm0.bias, norm1.weight, norm1.bias, norm2.weight, norm2.bias, norm3.weight, norm3.bias

2025-05-26 01:39:53,799 - mmseg - INFO - DTP(
  (backbone): SwinTransformer(
    (patch_embed): PatchEmbed(
      (adap_padding): AdaptivePadding()
      (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (drop_after_pos): Dropout(p=0.0, inplace=False)
    (stages): ModuleList(
      (0): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=128, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=512, out_features=128, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=512, out_features=256, bias=False)
        )
      )
      (1): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=1024, out_features=512, bias=False)
        )
      )
      (2): SwinBlockSequence(
        (blocks): ModuleList(
          (0-17): 18 x SwinBlock(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=512, out_features=2048, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=512, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        )
      )
      (3): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
      )
    )
    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'checkpoints/simmim_pretrain__swin_base__img192_window6__800ep.pth'}
  (decode_head): IAParser(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=True)
    (conv_seg): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (0): Sequential(
        (0): AdaptiveAvgPool2d(output_size=1)
        (1): ConvModule(
          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): AdaptiveAvgPool2d(output_size=2)
        (1): ConvModule(
          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): AdaptiveAvgPool2d(output_size=3)
        (1): ConvModule(
          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (3): Sequential(
        (0): AdaptiveAvgPool2d(output_size=6)
        (1): ConvModule(
          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(3072, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0-2): 3 x ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ill_transform): Sequential(
      (0): ConvModule(
        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (ill_ppm): PPM(
      (0): Sequential(
        (0): AdaptiveAvgPool2d(output_size=1)
        (1): ConvModule(
          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): AdaptiveAvgPool2d(output_size=2)
        (1): ConvModule(
          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): AdaptiveAvgPool2d(output_size=3)
        (1): ConvModule(
          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (3): Sequential(
        (0): AdaptiveAvgPool2d(output_size=6)
        (1): ConvModule(
          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (ill_bottleneck): ConvModule(
      (conv): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (conv_ill_seg): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))
    (mask_ill_layer): Sequential(
      (0): ConvModule(
        (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
      (2): Sigmoid()
    )
    (conv_all_seg): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (disentangle_head): SODHead(
    (loss_retinex): PixelLoss(
      (creterion): MSELoss()
    )
    (loss_smooth): SmoothLoss()
    (stem): ConvModule(
      (padding_layer): ReflectionPad2d((3, 3, 3, 3))
      (conv): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)
      (in): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (activate): ReLU(inplace=True)
    )
    (downsample): Sequential(
      (0): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (in): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
    )
    (residual): Sequential(
      (0): ResidualBlock(
        (block): Sequential(
          (0): ConvModule(
            (padding_layer): ReflectionPad2d((1, 1, 1, 1))
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
            (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (padding_layer): ReflectionPad2d((1, 1, 1, 1))
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
            (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (1): ResidualBlock(
        (block): Sequential(
          (0): ConvModule(
            (padding_layer): ReflectionPad2d((1, 1, 1, 1))
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
            (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (padding_layer): ReflectionPad2d((1, 1, 1, 1))
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
            (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
    )
    (light_attention): LightAttention(
      (blocks): ModuleList(
        (0-1): 2 x SwinBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): ShiftWindowMSA(
            (w_msa): WindowMSA(
              (qkv): Linear(in_features=128, out_features=384, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop): DropPath()
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (ffn): FFN(
            (activate): GELU(approximate='none')
            (layers): Sequential(
              (0): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0, inplace=False)
              )
              (1): Linear(in_features=512, out_features=128, bias=True)
              (2): Dropout(p=0, inplace=False)
            )
            (dropout_layer): DropPath()
          )
        )
      )
      (in_transform): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (activate): GELU(approximate='none')
      )
      (out_transform): Sequential(
        (0): Linear(in_features=128, out_features=16, bias=True)
        (1): Sigmoid()
      )
      (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (up): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')
    )
    (image_pool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
      (2): ReLU(inplace=True)
    )
    (merge): ConvModule(
      (padding_layer): ReflectionPad2d((1, 1, 1, 1))
      (conv): Conv2d(176, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (in): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (activate): ReLU(inplace=True)
    )
    (upsample_illumination): Sequential(
      (0): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (in): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
      (1): Upsample(scale_factor=2.0, mode='bilinear')
      (2): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (in): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
      (3): Upsample(scale_factor=2.0, mode='bilinear')
    )
    (upsample_reflectance): Sequential(
      (0): Upsample(scale_factor=2.0, mode='bilinear')
      (1): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (in): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
      (2): Upsample(scale_factor=2.0, mode='bilinear')
      (3): ConvModule(
        (padding_layer): ReflectionPad2d((1, 1, 1, 1))
        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (in): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (activate): ReLU(inplace=True)
      )
      (4): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
    )
    (refine_reflectance): ConvModule(
      (padding_layer): ReflectionPad2d((1, 1, 1, 1))
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (in): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (activate): ReLU(inplace=True)
    )
    (reflectance_output): Sequential(
      (0): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)
      (1): Tanh()
    )
    (illumination_output): Sequential(
      (0): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)
      (1): Sigmoid()
    )
  )
  init_cfg={'type': 'Kaiming', 'override': {'type': 'Constant', 'layer': 'Conv2d', 'name': 'reflectance_output', 'val': 0.0, 'bias': 0.5}}
  (disentanlge_loss): PixelLoss(
    (creterion): L1Loss()
  )
)
2025-05-26 01:39:53,832 - mmseg - INFO - Loaded 2248 images
2025-05-26 01:39:53,859 - mmseg - INFO - Loaded 2248 images
2025-05-26 01:39:55,382 - mmseg - INFO - Loaded 1299 images
2025-05-26 01:39:55,383 - mmseg - INFO - load checkpoint from local path: work_dirs/night_base/latest.pth
2025-05-26 01:40:02,227 - mmseg - INFO - resumed from epoch: 47, iter 50999
2025-05-26 01:40:02,228 - mmseg - INFO - Start running, host: beleznai@i64, work_dir: /home/beleznai/git/VI_Project/work_dirs/night_base
2025-05-26 01:40:02,228 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-26 01:40:02,229 - mmseg - INFO - workflow: [('train', 1)], max: 60000 iters
2025-05-26 01:40:02,231 - mmseg - INFO - Checkpoints will be saved to /home/beleznai/git/VI_Project/work_dirs/night_base by HardDiskBackend.
